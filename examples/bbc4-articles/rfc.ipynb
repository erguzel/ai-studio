{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exchelp.exception_helper import ReportObject, CoreException, object_from_module\n",
    "\n",
    "import os\n",
    "#\n",
    "# Model Parameters\n",
    "#\n",
    "\n",
    "main_report = ReportObject().adddata('_title_',os.path.basename('rfc.ipynb')).\\\n",
    "    adddata('initialize_info',ReportObject().\\\n",
    "        adddata('source',r\"data/raw/bbc4\").\\\n",
    "        adddata('extension','.txt').\\\n",
    "        adddata('type','text-document')\n",
    "    ).\\\n",
    "    adddata('cleanse_info',ReportObject().\\\n",
    "        adddata('char_cleaner_function',ReportObject().\\\n",
    "            adddata('module','aistudio.data.text_utils').\\\n",
    "            adddata('object','clear_default_chars')\n",
    "\n",
    "        ).\\\n",
    "        adddata('stemming_lemmatization_function',ReportObject().\\\n",
    "            adddata('module','aistudio.data.text_utils').\\\n",
    "            adddata('object','stemming_lematization')\n",
    "        ).\\\n",
    "        adddata('stemmer_or_lemmatizer_instance',ReportObject().\\\n",
    "                adddata('module','nltk.stem').\\\n",
    "                adddata('object','WordNetLemmatizer')\n",
    "            )\n",
    "    ).\\\n",
    "    adddata('prepare_info',ReportObject().\\\n",
    "        adddata('vectorizer_instance',ReportObject().\\\n",
    "            adddata('module','sklearn.feature_extraction.text').\\\n",
    "            adddata('object','CountVectorizer').\\\n",
    "            adddata('hyper_params',ReportObject().\\\n",
    "                adddata('max_features',1500).\\\n",
    "                adddata('min_df',5).\\\n",
    "                adddata('max_df',0.7)\n",
    "            ).\\\n",
    "            adddata('stop_words_function',ReportObject().\\\n",
    "                    adddata('module','nltk.corpus').\\\n",
    "                    adddata('object','stopwords').\\\n",
    "                    adddata('subObject','words')\n",
    "            ).\\\n",
    "            adddata('language','english')\n",
    "        ).\\\n",
    "        adddata('transformer_instance',ReportObject().\\\n",
    "            adddata('module','sklearn.feature_extraction.text').\\\n",
    "            adddata('object','TfidfTransformer')\n",
    "        ).\\\n",
    "        adddata('test_size',0.2).\\\n",
    "        adddata('random_state',0)\n",
    "    ).\\\n",
    "    adddata('execute_info',ReportObject().\\\n",
    "        adddata('model_instance',ReportObject().\\\n",
    "            adddata('module','sklearn.ensemble').\n",
    "            adddata('object','RandomForestClassifier').\\\n",
    "            adddata('hyper_params',ReportObject().\\\n",
    "                adddata('n_estimators',1000).\\\n",
    "                adddata('random_state',0)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"message\": \"data load failed\",\n",
      " \"dontthrow\": true,\n",
      " \"logit\": true,\n",
      " \"_file\": \"/var/folders/c9/912h9yrs5jbdsvklgxszk8br0000gn/T/ipykernel_16192/1631172714.py\",\n",
      " \"_line\": 9,\n",
      " \"shouldexit\": true,\n",
      " \"_timeStamp\": \"2022-12-23 17:20:43.712652\",\n",
      " \"_env\": \"oe-ws-main.local\",\n",
      " \"_class\": \"CoreException\",\n",
      " \"_cause\": {\n",
      "  \"_repr\": \"FileNotFoundError(2, 'No such file or directory')\"\n",
      " },\n",
      " \"_repr\": \"CoreException('data load failed', FileNotFoundError(2, 'No such file or directory'))\"\n",
      "}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     movie_data \u001b[39m=\u001b[39m load_files(data_source)\n\u001b[1;32m     10\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/ai-studio-env/lib/python3.10/site-packages/sklearn/datasets/_base.py:218\u001b[0m, in \u001b[0;36mload_files\u001b[0;34m(container_path, description, categories, load_content, shuffle, encoding, decode_error, random_state, allowed_extensions)\u001b[0m\n\u001b[1;32m    215\u001b[0m filenames \u001b[39m=\u001b[39m []\n\u001b[1;32m    217\u001b[0m folders \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 218\u001b[0m     f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(listdir(container_path)) \u001b[39mif\u001b[39;00m isdir(join(container_path, f))\n\u001b[1;32m    219\u001b[0m ]\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m categories \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'examples/bbc4-articles/data/raw/bbc4'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     movie_data \u001b[39m=\u001b[39m load_files(data_source)\n\u001b[1;32m     10\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 11\u001b[0m     CoreException(\u001b[39m'\u001b[39;49m\u001b[39mdata load failed\u001b[39;49m\u001b[39m'\u001b[39;49m,e,logIt\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,dontThrow\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,shouldExit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mact()\n\u001b[1;32m     12\u001b[0m X, y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(movie_data\u001b[39m.\u001b[39mdata), np\u001b[39m.\u001b[39marray(movie_data\u001b[39m.\u001b[39mtarget)\n\u001b[1;32m     14\u001b[0m main_report\u001b[39m.\u001b[39mgetdata(\u001b[39m'\u001b[39m\u001b[39minitialize_info\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mraw_number\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X)\n",
      "File \u001b[0;32m~/.local/anaconda3/envs/ai-studio-env/lib/python3.10/site-packages/exchelp/exception_helper.py:105\u001b[0m, in \u001b[0;36mCoreException.act\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshouldexit):\n\u001b[0;32m--> 105\u001b[0m     exit(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import  load_files\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Initialize\n",
    "#\n",
    "data_source = main_report.getdata('initialize_info')['source']\n",
    "print(data_source)\n",
    "try:\n",
    "    movie_data = load_files(data_source)\n",
    "except Exception as e:\n",
    "    CoreException('data load failed',e,logIt=True,dontThrow=True,shouldExit=True).act()\n",
    "X, y = np.array(movie_data.data), np.array(movie_data.target)\n",
    "\n",
    "main_report.getdata('initialize_info')['raw_number']=len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Cleanse\n",
    "#\n",
    "from aistudio.reflection import runtime_objects\n",
    "\n",
    "#char cleaning\n",
    "moduleName = main_report.getData('cleanse_info')['char_cleaner_function']['module']\n",
    "objectName = main_report.getData('cleanse_info')['char_cleaner_function']['object']\n",
    "docs = runtime_objects.object_from_module(moduleName=moduleName,objectName=objectName)(data=X)\n",
    "\n",
    "#stemming-lemmatization cleaning\n",
    "moduleName = main_report.getData('cleanse_info')['stemmer_or_lemmatizer_instance']['module']\n",
    "objectName = main_report.getData('cleanse_info')['stemmer_or_lemmatizer_instance']['object']\n",
    "stem_or_lemmatizer_instance = runtime_objects.object_from_module(moduleName=moduleName,objectName=objectName)()\n",
    "\n",
    "moduleName = main_report.getData('cleanse_info')['stemming_lemmatization_function']['module']\n",
    "objectName = main_report.getData('cleanse_info')['stemming_lemmatization_function']['object']\n",
    "docs = runtime_objects.object_from_module(moduleName=moduleName,objectName=objectName)(stem_or_lemmatizer=stem_or_lemmatizer_instance,data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prepare\n",
    "#\n",
    "\n",
    "#   stopwords\n",
    "moduleName = main_report.getData('prepare_info')['vectorizer_instance']['stop_words_function']['module']\n",
    "objectName = main_report.getData('prepare_info')['vectorizer_instance']['stop_words_function']['object']\n",
    "subObjectName = main_report.getData('prepare_info')['vectorizer_instance']['stop_words_function']['subObject']\n",
    "stop_words_language = main_report.getData('prepare_info')['vectorizer_instance']['language']\n",
    "stop_words = runtime_objects.object_from_module(moduleName=moduleName,objectName=objectName,subObjectName=subObjectName)(stop_words_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   vectorizer\n",
    "vectorizer_instance_params = main_report.getData('prepare_info')['vectorizer_instance']['hyper_params']\n",
    "moduleName = main_report.getData('prepare_info')['vectorizer_instance']['module']\n",
    "objectName = main_report.getData('prepare_info')['vectorizer_instance']['object']\n",
    "vectorizer_instance = runtime_objects.object_from_module(moduleName,objectName)(**vectorizer_instance_params,stop_words = stop_words)\n",
    "\n",
    "vectorized_count = vectorizer_instance.fit_transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   transformer\n",
    "moduleName = main_report.getData('prepare_info')['transformer_instance']['module']\n",
    "objectName = main_report.getData('prepare_info')['transformer_instance']['object']\n",
    "transformer_instance = runtime_objects.object_from_module(moduleName=moduleName,objectName=objectName)()\n",
    "\n",
    "transformed_vector = transformer_instance.fit_transform(vectorized_count).toarray()\n",
    "\n",
    "test_size = objectName = main_report.getData('prepare_info')['test_size']\n",
    "random_state = objectName = main_report.getData('prepare_info')['random_state']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_vector, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Execute\n",
    "#\n",
    "moduleName = main_report.getData('execute_info')['model_instance']['module']\n",
    "objectName = main_report.getData('execute_info')['model_instance']['object']\n",
    "model_instance_parameters = main_report.getData('execute_info')['model_instance']['hyper_params']\n",
    "model_instance = runtime_objects.object_from_module(moduleName=moduleName,objectName=objectName)(**model_instance_parameters)\n",
    "model_instance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.94      0.93      0.94       102\n",
      "entertainment       0.98      0.94      0.96        84\n",
      "     politics       0.95      0.92      0.94        78\n",
      "        sport       0.97      1.00      0.99       103\n",
      "         tech       0.95      0.99      0.97        78\n",
      "\n",
      "     accuracy                           0.96       445\n",
      "    macro avg       0.96      0.96      0.96       445\n",
      " weighted avg       0.96      0.96      0.96       445\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ReportObject()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Reportize\n",
    "#\n",
    "from sklearn.metrics import classification_report\n",
    "import sys\n",
    "\n",
    "\n",
    "y_pred = model_instance.predict(X_test)\n",
    "target_names = ['business', 'entertainment', 'politics','sport','tech']\n",
    "classification_performance = classification_report(y_test, y_pred, target_names=target_names,output_dict=True)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "model_name = main_report.getData('execute_info')['model_instance']['object']+'.sav'\n",
    "run_title = main_report.getData('_title_')\n",
    "\n",
    "main_report.addData('metric_info',rep_util.ReportObject().\\\n",
    "    addData('model_name',model_name).\\\n",
    "    addData('model_size',sys.getsizeof(model_instance)).\\\n",
    "    addData('target_names',target_names).\\\n",
    "    addData('summary',classification_performance)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Persist\n",
    "\n",
    "rep_util.persist_model(model_name,model_instance,main_report,run_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-studio-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "69f43e4e88b3450101ed86a8083b813d05d9b24811077b5788d6b86b166cba6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
