{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exchelp.exception_helper import ReportObject, CoreException\n",
    "from aistudio.model.model_utils import persist_ml_model\n",
    "from aistudio.data.meta.module_utils import object_from_module\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# Model Parameters\n",
    "#\n",
    "\n",
    "main_report = ReportObject().adddata('_title_',os.path.basename('rfc.ipynb')).\\\n",
    "    adddata('initialize_info',ReportObject().\\\n",
    "        adddata('source',r\"data/raw/bbc4\").\\\n",
    "        adddata('extension','.txt').\\\n",
    "        adddata('type','text-document')\n",
    "    ).\\\n",
    "    adddata('cleanse_info',ReportObject().\\\n",
    "        adddata('char_cleaner_function',ReportObject().\\\n",
    "            adddata('module','aistudio.data.text_utils').\\\n",
    "            adddata('object','clear_default_chars')\n",
    "\n",
    "        ).\\\n",
    "        adddata('stemming_lemmatization_function',ReportObject().\\\n",
    "            adddata('module','aistudio.data.text_utils').\\\n",
    "            adddata('object','stemming_lematization')\n",
    "        ).\\\n",
    "        adddata('stemmer_or_lemmatizer_instance',ReportObject().\\\n",
    "                adddata('module','nltk.stem').\\\n",
    "                adddata('object','WordNetLemmatizer')\n",
    "            )\n",
    "    ).\\\n",
    "    adddata('prepare_info',ReportObject().\\\n",
    "        adddata('vectorizer_instance',ReportObject().\\\n",
    "            adddata('module','sklearn.feature_extraction.text').\\\n",
    "            adddata('object','CountVectorizer').\\\n",
    "            adddata('hyper_params',ReportObject().\\\n",
    "                adddata('max_features',1500).\\\n",
    "                adddata('min_df',5).\\\n",
    "                adddata('max_df',0.7)\n",
    "            ).\\\n",
    "            adddata('stop_words_function',ReportObject().\\\n",
    "                    adddata('module','nltk.corpus').\\\n",
    "                    adddata('object','stopwords').\\\n",
    "                    adddata('subObject','words')\n",
    "            ).\\\n",
    "            adddata('language','english')\n",
    "        ).\\\n",
    "        adddata('transformer_instance',ReportObject().\\\n",
    "            adddata('module','sklearn.feature_extraction.text').\\\n",
    "            adddata('object','TfidfTransformer')\n",
    "        ).\\\n",
    "        adddata('test_size',0.2).\\\n",
    "        adddata('random_state',0)\n",
    "    ).\\\n",
    "    adddata('execute_info',ReportObject().\\\n",
    "        adddata('model_instance',ReportObject().\\\n",
    "            adddata('module','sklearn.ensemble').\n",
    "            adddata('object','RandomForestClassifier').\\\n",
    "            adddata('hyper_params',ReportObject().\\\n",
    "                adddata('n_estimators',1000).\\\n",
    "                adddata('random_state',0)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/bbc4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import  load_files\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Initialize\n",
    "#\n",
    "data_source = main_report.getdata('initialize_info')['source']\n",
    "print(data_source)\n",
    "try:\n",
    "    movie_data = load_files(data_source)\n",
    "except Exception as e:\n",
    "    CoreException('data load failed',e,logIt=True,dontThrow=True,shouldExit=True).act()\n",
    "X, y = np.array(movie_data.data), np.array(movie_data.target)\n",
    "\n",
    "main_report.getdata('initialize_info')['raw_number']=len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Cleanse\n",
    "#\n",
    "\n",
    "#char cleaning\n",
    "moduleName = main_report.getdata('cleanse_info')['char_cleaner_function']['module']\n",
    "objectName = main_report.getdata('cleanse_info')['char_cleaner_function']['object']\n",
    "docs = object_from_module(moduleName=moduleName,objectName=objectName)(data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming-lemmatization cleaning\n",
    "moduleName = main_report.getdata('cleanse_info')['stemmer_or_lemmatizer_instance']['module']\n",
    "objectName = main_report.getdata('cleanse_info')['stemmer_or_lemmatizer_instance']['object']\n",
    "stem_or_lemmatizer_instance = object_from_module(moduleName=moduleName,objectName=objectName)()\n",
    "\n",
    "moduleName = main_report.getdata('cleanse_info')['stemming_lemmatization_function']['module']\n",
    "objectName = main_report.getdata('cleanse_info')['stemming_lemmatization_function']['object']\n",
    "docs = object_from_module(moduleName=moduleName,objectName=objectName)(stem_or_lemmatizer=stem_or_lemmatizer_instance,data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   stopwords\n",
    "moduleName = main_report.getdata('prepare_info')['vectorizer_instance']['stop_words_function']['module']\n",
    "objectName = main_report.getdata('prepare_info')['vectorizer_instance']['stop_words_function']['object']\n",
    "subObjectName = main_report.getdata('prepare_info')['vectorizer_instance']['stop_words_function']['subObject']\n",
    "stop_words_language = main_report.getdata('prepare_info')['vectorizer_instance']['language']\n",
    "stop_words = object_from_module(moduleName=moduleName,objectName=objectName,subObjectName=subObjectName)(stop_words_language)\n",
    "\n",
    "#   vectorizer\n",
    "vectorizer_instance_params = main_report.getdata('prepare_info')['vectorizer_instance']['hyper_params']\n",
    "moduleName = main_report.getdata('prepare_info')['vectorizer_instance']['module']\n",
    "objectName = main_report.getdata('prepare_info')['vectorizer_instance']['object']\n",
    "vectorizer_instance = object_from_module(moduleName,objectName)(**vectorizer_instance_params,stop_words = stop_words)\n",
    "vectorized_count = vectorizer_instance.fit_transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   transformer\n",
    "moduleName = main_report.getdata('prepare_info')['transformer_instance']['module']\n",
    "objectName = main_report.getdata('prepare_info')['transformer_instance']['object']\n",
    "transformer_instance = object_from_module(moduleName=moduleName,objectName=objectName)()\n",
    "transformed_vector = transformer_instance.fit_transform(vectorized_count).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "\n",
    "test_size = objectName = main_report.getdata('prepare_info')['test_size']\n",
    "random_state = objectName = main_report.getdata('prepare_info')['random_state']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_vector, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Execute\n",
    "#\n",
    "moduleName = main_report.getdata('execute_info')['model_instance']['module']\n",
    "objectName = main_report.getdata('execute_info')['model_instance']['object']\n",
    "model_instance_parameters = main_report.getdata('execute_info')['model_instance']['hyper_params']\n",
    "model_instance = object_from_module(moduleName=moduleName,objectName=objectName)(**model_instance_parameters)\n",
    "model_instance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.94      0.93      0.94       102\n",
      "entertainment       0.98      0.94      0.96        84\n",
      "     politics       0.95      0.92      0.94        78\n",
      "        sport       0.97      1.00      0.99       103\n",
      "         tech       0.95      0.99      0.97        78\n",
      "\n",
      "     accuracy                           0.96       445\n",
      "    macro avg       0.96      0.96      0.96       445\n",
      " weighted avg       0.96      0.96      0.96       445\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ReportObject()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Reportize\n",
    "#\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model_instance.predict(X_test)\n",
    "target_names = ['business', 'entertainment', 'politics','sport','tech']\n",
    "classification_performance = classification_report(y_test, y_pred, target_names=target_names,output_dict=True)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "model_name = main_report.getdata('execute_info')['model_instance']['object']+'.sav'\n",
    "run_title = main_report.getdata('_title_')\n",
    "\n",
    "main_report.adddata('metric_info',ReportObject().\\\n",
    "    adddata('model_name',model_name).\\\n",
    "    adddata('target_names',target_names).\\\n",
    "    adddata('summary',classification_performance)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist\n",
    "\n",
    "persist_ml_model(modelName=model_name,trainedModel = model_instance,runTitle=run_title,mainReport=main_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-studio-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "69f43e4e88b3450101ed86a8083b813d05d9b24811077b5788d6b86b166cba6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
